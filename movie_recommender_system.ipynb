{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a6c9ef7",
   "metadata": {},
   "source": [
    "# Movie Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ed5b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in d:\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (1.6.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (3.9.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: click in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy scikit-learn nltk tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6ea1a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3ba1c8",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "359eb567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies shape: (45466, 24)\n",
      "Credits shape: (45476, 3)\n"
     ]
    }
   ],
   "source": [
    "movies_path = \"movies_metadata.csv\"\n",
    "credits_path = \"credits.csv\"\n",
    "\n",
    "movies = pd.read_csv(movies_path, low_memory=False)\n",
    "credits = pd.read_csv(credits_path)\n",
    "\n",
    "print(\"Movies shape:\", movies.shape)\n",
    "print(\"Credits shape:\", credits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441b229b",
   "metadata": {},
   "source": [
    "### CLEAN & PREP IDs, MERGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0142cc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged df shape: (45539, 26)\n",
      "Columns in use: ['id', 'title', 'overview', 'genres', 'cast', 'crew']\n",
      "                                                          0  \\\n",
      "id                                                      862   \n",
      "title                                             Toy Story   \n",
      "overview  Led by Woody, Andy's toys live happily in his ...   \n",
      "genres    [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
      "cast      [{'cast_id': 14, 'character': 'Woody (voice)',...   \n",
      "crew      [{'credit_id': '52fe4284c3a36847f8024f49', 'de...   \n",
      "\n",
      "                                                          1  \n",
      "id                                                     8844  \n",
      "title                                               Jumanji  \n",
      "overview  When siblings Judy and Peter discover an encha...  \n",
      "genres    [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...  \n",
      "cast      [{'cast_id': 1, 'character': 'Alan Parrish', '...  \n",
      "crew      [{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...  \n"
     ]
    }
   ],
   "source": [
    "# movies id sometimes non-numeric; coerce to numeric\n",
    "movies['id'] = pd.to_numeric(movies['id'], errors='coerce')\n",
    "credits['id'] = pd.to_numeric(credits['id'], errors='coerce')\n",
    "\n",
    "# Drop rows where id is NaN\n",
    "movies = movies.dropna(subset=['id'])\n",
    "credits = credits.dropna(subset=['id'])\n",
    "\n",
    "# Convert to int for safe merging\n",
    "movies['id'] = movies['id'].astype(int)\n",
    "credits['id'] = credits['id'].astype(int)\n",
    "\n",
    "# Merge on 'id'\n",
    "df = movies.merge(credits, on='id', how='left')\n",
    "print(\"Merged df shape:\", df.shape)\n",
    "\n",
    "# FIX: Select only existing columns safely \n",
    "available_cols = df.columns.tolist()\n",
    "required_cols = ['id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']\n",
    "\n",
    "# Filter to keep only the ones that actually exist\n",
    "selected_cols = [col for col in required_cols if col in available_cols]\n",
    "df = df[selected_cols]\n",
    "\n",
    "print(\"Columns in use:\", selected_cols)\n",
    "print(df.head(2).T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8521e79",
   "metadata": {},
   "source": [
    "### PARSERS: genres, keywords, cast, crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ccbe996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45539/45539 [00:02<00:00, 21497.20it/s]\n",
      "100%|██████████| 45539/45539 [00:32<00:00, 1413.53it/s]\n",
      "100%|██████████| 45539/45539 [00:25<00:00, 1796.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         title                 genres_parsed keywords_parsed  \\\n",
      "0                    Toy Story   [Animation, Comedy, Family]              []   \n",
      "1                      Jumanji  [Adventure, Fantasy, Family]              []   \n",
      "2             Grumpier Old Men             [Romance, Comedy]              []   \n",
      "3            Waiting to Exhale      [Comedy, Drama, Romance]              []   \n",
      "4  Father of the Bride Part II                      [Comedy]              []   \n",
      "\n",
      "                                         cast_parsed         director  \n",
      "0                [Tom Hanks, Tim Allen, Don Rickles]    John Lasseter  \n",
      "1     [Robin Williams, Jonathan Hyde, Kirsten Dunst]     Joe Johnston  \n",
      "2         [Walter Matthau, Jack Lemmon, Ann-Margret]    Howard Deutch  \n",
      "3  [Whitney Houston, Angela Bassett, Loretta Devine]  Forest Whitaker  \n",
      "4         [Steve Martin, Diane Keaton, Martin Short]    Charles Shyer  \n"
     ]
    }
   ],
   "source": [
    "# Helper: safely parse JSON-like string column to Python list/dict \n",
    "def parse_json_field(x):\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    try:\n",
    "        return ast.literal_eval(x)\n",
    "    except Exception:\n",
    "        try:\n",
    "            s = x.replace(\"'\", '\"')\n",
    "            return ast.literal_eval(s)\n",
    "        except Exception:\n",
    "            return []\n",
    "\n",
    "# Extract genre names from genres column \n",
    "def extract_genres(genres_field):\n",
    "    parsed = parse_json_field(genres_field)\n",
    "    return [g.get('name', '') for g in parsed if isinstance(g, dict) and g.get('name')]\n",
    "\n",
    "# Extract keywords (only if available) \n",
    "def extract_keywords(keywords_field):\n",
    "    parsed = parse_json_field(keywords_field)\n",
    "    return [k.get('name', '') for k in parsed if isinstance(k, dict) and k.get('name')]\n",
    "\n",
    "# Extract top N cast names (actors) \n",
    "def extract_cast(cast_field, top_n=3):\n",
    "    parsed = parse_json_field(cast_field)\n",
    "    names = []\n",
    "    for c in parsed:\n",
    "        if isinstance(c, dict) and c.get('name'):\n",
    "            names.append(c['name'])\n",
    "        if len(names) >= top_n:\n",
    "            break\n",
    "    return names\n",
    "\n",
    "# Extract director from crew \n",
    "def extract_director(crew_field):\n",
    "    parsed = parse_json_field(crew_field)\n",
    "    for c in parsed:\n",
    "        if isinstance(c, dict) and c.get('job') and c.get('name'):\n",
    "            if c.get('job').lower() == 'director':\n",
    "                return c.get('name')\n",
    "    return ''\n",
    "\n",
    "# Apply parsers safely \n",
    "tqdm.pandas()\n",
    "\n",
    "# Apply only on columns that exist\n",
    "if 'genres' in df.columns:\n",
    "    df['genres_parsed'] = df['genres'].progress_apply(extract_genres)\n",
    "\n",
    "if 'keywords' in df.columns:\n",
    "    df['keywords_parsed'] = df['keywords'].progress_apply(extract_keywords)\n",
    "else:\n",
    "    df['keywords_parsed'] = [[] for _ in range(len(df))]  # empty placeholder\n",
    "\n",
    "if 'cast' in df.columns:\n",
    "    df['cast_parsed'] = df['cast'].progress_apply(extract_cast)\n",
    "\n",
    "if 'crew' in df.columns:\n",
    "    df['director'] = df['crew'].progress_apply(extract_director)\n",
    "\n",
    "#  Quick check \n",
    "print(df[['title', 'genres_parsed', 'keywords_parsed', 'cast_parsed', 'director']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e477d2",
   "metadata": {},
   "source": [
    "### BUILD \"tags\" (bag of words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd241384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45539/45539 [00:03<00:00, 12670.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags sample:\n",
      "                                                       0  \\\n",
      "title                                          Toy Story   \n",
      "tags   animation comedy family tomhanks timallen rick...   \n",
      "\n",
      "                                                       1  \\\n",
      "title                                            Jumanji   \n",
      "tags   adventure fantasy family robinwilliams jonatha...   \n",
      "\n",
      "                                                       2  \\\n",
      "title                                   Grumpier Old Men   \n",
      "tags   romance comedy waltermatthau jacklemmon annmar...   \n",
      "\n",
      "                                                       3  \\\n",
      "title                                  Waiting to Exhale   \n",
      "tags   comedy drama romance whitneyhouston angelabass...   \n",
      "\n",
      "                                                       4  \n",
      "title                        Father of the Bride Part II  \n",
      "tags   comedy stevemartin dianekeaton martinshort cha...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Text cleaning helper\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_and_join(list_of_strings):\n",
    "    # keep only alphanumeric, remove spaces in multi-word tokens by joining with ''\n",
    "    # lower, remove punctuation\n",
    "    cleaned = []\n",
    "    for s in list_of_strings:\n",
    "        if not isinstance(s, str):\n",
    "            continue\n",
    "        # remove punctuation\n",
    "        s2 = re.sub(r'[^a-zA-Z0-9\\s]', '', s)\n",
    "        # lowercase, strip\n",
    "        s2 = s2.lower().strip()\n",
    "        # split to tokens and remove stopwords\n",
    "        tokens = [tok for tok in s2.split() if tok not in stop_words]\n",
    "        # join tokens to single token to preserve multi-word as single token\n",
    "        if tokens:\n",
    "            cleaned.append(''.join(tokens))\n",
    "    return \" \".join(cleaned)\n",
    "\n",
    "# For overview, do a mild cleaning (keep words)\n",
    "def clean_overview(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
    "    text = text.lower()\n",
    "    tokens = [tok for tok in text.split() if tok not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Create tags column: genres + keywords + cast + director + overview\n",
    "def create_tags(row):\n",
    "    parts = []\n",
    "    # genres_parsed: list of genre names\n",
    "    parts.extend(row['genres_parsed'] if isinstance(row['genres_parsed'], list) else [])\n",
    "    # keywords_parsed\n",
    "    parts.extend(row['keywords_parsed'] if isinstance(row['keywords_parsed'], list) else [])\n",
    "    # cast_parsed (top actors)\n",
    "    parts.extend(row['cast_parsed'] if isinstance(row['cast_parsed'], list) else [])\n",
    "    # director\n",
    "    if row['director']:\n",
    "        parts.append(row['director'])\n",
    "    # overview (just raw cleaned words)\n",
    "    overview = clean_overview(row['overview'])\n",
    "    # Now clean and join token lists\n",
    "    tag_text = clean_and_join(parts)\n",
    "    if overview:\n",
    "        # include overview too (space separated tokens)\n",
    "        tag_text = tag_text + \" \" + overview\n",
    "    return tag_text\n",
    "\n",
    "# Compute tags (may take some time)\n",
    "df['tags'] = df.progress_apply(create_tags, axis=1)\n",
    "\n",
    "# Basic stats\n",
    "print(\"Tags sample:\")\n",
    "print(df[['title','tags']].head(5).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aadaed",
   "metadata": {},
   "source": [
    "### VECTORIZE & COMPUTE SIMILARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d57807b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags matrix shape: (5000, 5000)\n",
      "Cosine similarity computed (sparse), shape: (5000, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Limit to smaller subset (for memory safety)\n",
    "df_small = df.head(5000).copy()  # Adjust this depending on your RAM\n",
    "\n",
    "cv = CountVectorizer(max_features=5000, stop_words='english')\n",
    "tags_matrix = cv.fit_transform(df_small['tags'].fillna(''))\n",
    "\n",
    "print(\"Tags matrix shape:\", tags_matrix.shape)\n",
    "\n",
    "# Use sparse output to save RAM\n",
    "cosine_sim = cosine_similarity(tags_matrix, tags_matrix, dense_output=False)\n",
    "print(\"Cosine similarity computed (sparse), shape:\", cosine_sim.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a34201",
   "metadata": {},
   "source": [
    "### HELPER: MAP TITLE -> INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab5f426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some titles are duplicated; we'll keep the first occurrence mapping.\n",
    "df = df.reset_index(drop=True)\n",
    "title_to_idx = pd.Series(df.index, index=df['title'].str.lower()).drop_duplicates()\n",
    "\n",
    "def get_index_by_title(title):\n",
    "    \"\"\"\n",
    "    Return index for a title (case-insensitive). If exact title not found, try fuzzy match later.\n",
    "    \"\"\"\n",
    "    title_lower = title.lower()\n",
    "    if title_lower in title_to_idx:\n",
    "        return int(title_to_idx[title_lower])\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c625ad2d",
   "metadata": {},
   "source": [
    "### RECOMMEND FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b85fe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(movie_title, n_recommendations=10):\n",
    "    idx = get_index_by_title(movie_title)\n",
    "    if idx is None:\n",
    "        # try relaxed matching: substring search\n",
    "        possible = df[df['title'].str.lower().str.contains(movie_title.lower(), na=False)]\n",
    "        if len(possible) > 0:\n",
    "            idx = int(possible.index[0])\n",
    "            print(f\"Note: exact match not found. Using close match: '{df.loc[idx, 'title']}'\")\n",
    "        else:\n",
    "            raise ValueError(f\"Movie title '{movie_title}' not found in database.\")\n",
    "    # get similarity scores for this movie\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    # sort by score descending, skip the movie itself\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    # collect top n_recommendations (excluding itself)\n",
    "    results = []\n",
    "    count = 0\n",
    "    for i, score in sim_scores:\n",
    "        if i == idx:\n",
    "            continue\n",
    "        results.append((df.loc[i, 'title'], df.loc[i, 'id'], float(score)))\n",
    "        count += 1\n",
    "        if count >= n_recommendations:\n",
    "            break\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92305fc0",
   "metadata": {},
   "source": [
    "### USAGE EXAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5543035f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example recommendations for 'Toy Story':\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nExample recommendations for 'Toy Story':\")\n",
    "try:\n",
    "    recs = recommend(\"Toy Story\", n_recommendations=10)\n",
    "    for title, mid, score in recs:\n",
    "        print(f\"{title} (id={mid}) — similarity={score:.3f}\")\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fda44ae",
   "metadata": {},
   "source": [
    "### Streamlit app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e3ae896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# streamlit run app.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
